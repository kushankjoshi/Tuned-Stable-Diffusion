{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade jax jaxlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tEqPf_5djzK",
        "outputId": "548f6952-9166-4a7d-d071-c26dd87b585d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (0.4.33)\n",
            "Collecting jax\n",
            "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (0.4.33)\n",
            "Collecting jaxlib\n",
            "  Downloading jaxlib-0.4.34-cp310-cp310-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from jax) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax) (1.13.1)\n",
            "Downloading jax-0.4.34-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.4.34-cp310-cp310-manylinux2014_x86_64.whl (86.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.1/86.1 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jaxlib, jax\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.33\n",
            "    Uninstalling jaxlib-0.4.33:\n",
            "      Successfully uninstalled jaxlib-0.4.33\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.4.33\n",
            "    Uninstalling jax-0.4.33:\n",
            "      Successfully uninstalled jax-0.4.33\n",
            "Successfully installed jax-0.4.34 jaxlib-0.4.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSs4OeIrOHTd"
      },
      "outputs": [],
      "source": [
        "#https://machinelearningmastery.com/training-stable-diffusion-with-dreambooth/?ref=dailydev\n",
        "!wget -q https://github.com/kushankjoshi/Tuned-Stable-Diffusion/train_dreambooth.py\n",
        "!wget -q https://github.com/kushankjoshi/Tuned-Stable-Diffusion/convert_diffusers_to_original_stable_diffusion.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q -U --pre triton\n",
        "%pip install -q accelerate transformers ftfy bitsandbytes natsort safetensors xformers\n",
        "#%pip install --upgrade jax jaxlib\n",
        "%pip install -q diffusers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_boet-M0T0r3",
        "outputId": "b3c2535b-b8cf-42fe-a4c7-673ed2d639af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "from natsort import natsorted\n",
        "from glob import glob\n",
        "\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "6x7vdX0_OYTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.huggingface\n",
        "HUGGINGFACE_TOKEN = #Hugging Face Key\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token"
      ],
      "metadata": {
        "id": "2ZbagZaSOdRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VoG8FVm-p4l9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MODEL_NAME = \"runwayml/stable-diffusion-v1-5\"\n",
        "MODEL_NAME=\"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "OUTPUT_DIR = \"/content/stable_diffusion_weights/shk2\"\n",
        "\n",
        "# Create output directory\n",
        "!mkdir -p $OUTPUT_DIR"
      ],
      "metadata": {
        "id": "48QWQr8FPW_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The concepts_list is a list of concepts/subject, each represented as a dictionary\n",
        "concepts_list = [\n",
        "    {\n",
        "        \"instance_prompt\":   \"photo of shk2 women\",\n",
        "        \"class_prompt\":      \"photo of pregnant women in her 30s\",\n",
        "        \"instance_data_dir\": \"/content/data/shk\",\n",
        "        \"class_data_dir\":    \"/content/data/men\"\n",
        "    },\n",
        "]\n",
        "\n",
        "# Create a directory for each concept according to its instance_data_dir\n",
        "for c in concepts_list:\n",
        "    os.makedirs(c[\"instance_data_dir\"], exist_ok=True)\n",
        "\n",
        "#Dump the concepts_list to a JSON file\n",
        "with open(\"concepts_list.json\", \"w\") as f:\n",
        "    json.dump(concepts_list, f, indent=4)"
      ],
      "metadata": {
        "id": "SKw91D3IRMh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-ema\" \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "  --seed=1337 \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --train_text_encoder \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --use_8bit_adam \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --learning_rate=1e-6 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --num_class_images=50 \\\n",
        "  --sample_batch_size=4 \\\n",
        "  --max_train_steps=800 \\\n",
        "  --save_interval=10000 \\\n",
        "  --save_sample_prompt=\"photo of shk women\" \\\n",
        "  --concepts_list=\"concepts_list.json\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1L4JyjJSDLt",
        "outputId": "a42471d1-7832-4926-d662-359170f804f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-12 07:48:02.496005: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-12 07:48:02.516906: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-12 07:48:02.523141: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-12 07:48:03.832172: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/diffusers/configuration_utils.py:245: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.\n",
            "  deprecate(\"config-passed-as-path\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
            "Caching latents: 100% 50/50 [00:13<00:00,  3.83it/s]\n",
            "10/12/2024 07:49:07 - INFO - __main__ - ***** Running training *****\n",
            "10/12/2024 07:49:07 - INFO - __main__ -   Num examples = 50\n",
            "10/12/2024 07:49:07 - INFO - __main__ -   Num batches each epoch = 50\n",
            "10/12/2024 07:49:07 - INFO - __main__ -   Num Epochs = 16\n",
            "10/12/2024 07:49:07 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
            "10/12/2024 07:49:07 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "10/12/2024 07:49:07 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "10/12/2024 07:49:07 - INFO - __main__ -   Total optimization steps = 800\n",
            "Steps:   0% 0/800 [00:00<?, ?it/s]Traceback (most recent call last):\n",
            "  File \"/content/train_dreambooth.py\", line 869, in <module>\n",
            "    main(args)\n",
            "  File \"/content/train_dreambooth.py\", line 807, in main\n",
            "    model_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\", line 820, in forward\n",
            "    return model_forward(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\", line 808, in __call__\n",
            "    return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py\", line 43, in decorate_autocast\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/unets/unet_2d_condition.py\", line 1152, in forward\n",
            "    aug_emb = self.get_aug_embed(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/unets/unet_2d_condition.py\", line 969, in get_aug_embed\n",
            "    if \"text_embeds\" not in added_cond_kwargs:\n",
            "TypeError: argument of type 'NoneType' is not iterable\n",
            "Steps:   0% 0/800 [00:00<?, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WEIGHTS_DIR = natsorted(glob(OUTPUT_DIR + os.sep + \"*\"))[-1]\n",
        "print(WEIGHTS_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vbi194ctkS6C",
        "outputId": "326cb684-a24b-4f85-aa2e-3a8f8fda85a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stable_diffusion_weights/shk/800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WEIGHTS_DIR = natsorted(glob(OUTPUT_DIR + os.sep + \"*\"))[-1]\n",
        "print(WEIGHTS_DIR)\n",
        "ckpt_path = WEIGHTS_DIR + \"/model.ckpt\"\n",
        "\n",
        "half_arg = \"\"\n",
        "fp16 = True\n",
        "if fp16:\n",
        "    half_arg = \"--half\"\n",
        "!python convert_diffusers_to_original_stable_diffusion.py --model_path $WEIGHTS_DIR  --checkpoint_path $ckpt_path $half_arg\n",
        "print(f\"[*] Converted ckpt saved at {ckpt_path}\")\n",
        "\n",
        "WEIGHTS_DIR = natsorted(glob(OUTPUT_DIR + os.sep + \"*\"))[-1]\n",
        "ckpt_path = WEIGHTS_DIR + \"/model.ckpt\"\n",
        "\n",
        "half_arg = \"\"\n",
        "fp16 = True\n",
        "if fp16:\n",
        "    half_arg = \"--half\"\n",
        "!python convert_diffusers_to_original_stable_diffusion.py --model_path WEIGHTS_DIR  --checkpoint_path ckpt_path half_arg\n",
        "print(f\"[*] Converted ckpt saved at {ckpt_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8WnMd9iiUPT",
        "outputId": "d3429141-31d6-4d4f-cd67-748b791e94a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stable_diffusion_weights/shk/800\n",
            "[*] Converted ckpt saved at /content/stable_diffusion_weights/shk/800/model.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save tuned model in google drive"
      ],
      "metadata": {
        "id": "9qCiXrEvv47Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Copy the .ckpt file to Google Drive\n",
        "import shutil\n",
        "#ckpt_path='/content/stable_diffusion_weights/shk/800/'\n",
        "drive_path = \"/content/drive/MyDrive/StableDiffusion_Models/\"\n",
        "#os.makedirs(drive_path, exist_ok=True)\n",
        "shutil.copytree(ckpt_path, drive_path, dirs_exist_ok=True)\n",
        "print(f\"[*] Model saved to Google Drive at {drive_path + os.path.basename(ckpt_path)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99tmajpfuJLG",
        "outputId": "e89e62dd-e03a-4221-81cd-aa54e9e44a6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*] Model saved to Google Drive at /content/drive/MyDrive/StableDiffusion_Models/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validating tuned model"
      ],
      "metadata": {
        "id": "5mhtclFiof25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = WEIGHTS_DIR\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_path, safety_checker=None,\n",
        "                                               torch_dtype=torch.float16\n",
        "                                              ).to(\"cuda\")\n",
        "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "\n",
        "g_cuda = torch.Generator(device='cuda')\n",
        "seed = 52362\n",
        "g_cuda.manual_seed(seed)"
      ],
      "metadata": {
        "id": "Axg08OH7ojHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"photo of shk men in a space suite looking excited after landing in mars \"\n",
        "negative_prompt = \"\"\n",
        "num_samples = 4\n",
        "guidance_scale = 7.5\n",
        "num_inference_steps = 24\n",
        "height = 512\n",
        "width = 512\n",
        "\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)\n",
        "\n",
        "# Free runtime memory\n",
        "exit()"
      ],
      "metadata": {
        "id": "BVPIVCHMojyT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
